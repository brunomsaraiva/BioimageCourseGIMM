{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to scikit-learn and classical machine learning for image segmentation and classification\n",
    "\n",
    "In this notebook we are going to perform image segmentation using scikit-learn machine learning models.   \n",
    "We will be covering:\n",
    "1. Image Loading and normalization\n",
    "2. Unsupervised machine learning segmentation using k-means clustering\n",
    "3. Segmentation quality by measuring Intersection over Union (IoU)\n",
    "4. Creating extra features (data points) from pixel values\n",
    "5. Supervised machine learning with random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Let's start by installing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scikit_image scikit_learn matplotlib pandas -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Image Loading\n",
    "---\n",
    "Let's start by loading the image we want to segment using the [imread](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread) function of scikit-image, found in the io module.\n",
    "\n",
    "```python\n",
    "from skimage.io import imread\n",
    "image = imread(\"path/to/image\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "start by using the image found in `../data/images/wt_dna.tif`\n",
    "\n",
    "and then let's display it using [matplotlib imshow](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) function\n",
    "\n",
    "```python\n",
    "from matplotlib import pyplot as plt\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "```\n",
    "\n",
    "---\n",
    "  \n",
    "Note: when in doubt about a specific function you can always use the help function to get the documentation (`help(function_name)`) or, put the cursor inside the function you need help for and press `Shift+Tab` (_Note:_ only works in the browser) to get more information\n",
    "\n",
    "don't forget, you need to import it first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalize the intensity values of the image to range 0 to 1\n",
    "When dealing with machine learning approaches, images should be normalized for machine learning. This ensures that pixel values are scaled to a consistent range, typically between 0 and 1, which helps improve model convergence, reduces numerical instability, and ensures that features are treated uniformly during training.\n",
    "There are many ways to normalize images, for these exercises we will use [min-max Normalization](https://en.wikipedia.org/wiki/Normalization_(image_processing)).\n",
    "\n",
    "min-max Normalization is: \n",
    "\n",
    "$ I_{norm} = (I - I_{min})\\frac{newMax - newMin}{I_{max} - I_{min}} - newMin $\n",
    "\n",
    "Let's create our own normalization fuction using numpy array [min](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.min.html) and [max](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.max.html) methods to find the min and max values of the image and perform the calculation.\n",
    "We are also going to convert it's values to float precision by using the [astype](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.astype.html) method and numpy's float32 datatype.\n",
    "```python\n",
    "array.astype(np.float32)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Use the following skeleton for the function:\n",
    "\n",
    "_Hint_: newMax and newMin can be ommited since we want to normalize between 0 and 1\n",
    "\n",
    "Example code:\n",
    "```python\n",
    "import numpy as np # we need to import numpy as we will be using it\n",
    "def custom_normalize(input_image):\n",
    "    input_image = input_image.astype(np.float32)\n",
    "    input_max = # use np.max(input_image)\n",
    "    input_min = # use.np.min(input_image)\n",
    "    output = (input_image - input_min) / (input_max - input_min)\n",
    "    return output\n",
    "```\n",
    "\n",
    "Note: don't forget to import packages as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's:\n",
    "1. apply that function to the loaded image\n",
    "2. store the output in a new variable called \"normalized_image\"\n",
    "3. display the normalized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether the normalization worked by printing the minimum and maximum values of both images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using unsupervised machine learning for segmentation\n",
    "\n",
    "One of the great things about scikit-learn is that most machine learning models follow the same structure for their API:\n",
    "1. They are typically writen as Python classes that need to be initialized\n",
    "2. have a `.fit(data)` method to train\n",
    "3. a `.predict(data)` method to make predictions\n",
    "\n",
    "\n",
    "Example code:\n",
    "\n",
    "```python\n",
    "from sklearn.model_module import Model\n",
    "model = Model()\n",
    "model.fit(data2train) # typically expects an array with shape (n_samples, n_features)\n",
    "output = model.predict(data2predict) # same shape as data2train\n",
    "# then we need to reshape the output to the desired shape\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "We will start by trying to use the [K-Means clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) algorithm.\n",
    "For it's class initialization, we need to define the number of clusters we want to use. For binary segmentation, we will use 2 clusters.  \n",
    "    \n",
    "a) Import it and initialize it:\n",
    "```python\n",
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(2) # sets number of clusters to 2\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then let's reshape the data to the expected shape for the KMeans algorithm (n_samples, n_features).\n",
    "For this we will be using the [reshape](https://numpy.org/doc/stable/reference/generated/numpy.reshape.html) method of numpy:\n",
    "```python\n",
    "reshaped_array = array.reshape((-1, 1))\n",
    "```\n",
    "\n",
    "In this case we can consider the `n_samples` equal to `n_pixels` and `n_features` equal to it's value.  \n",
    "So it's final shape should correspond to `(n_pixels, 1)`\n",
    "\n",
    "b) reshape the array and store it in a new variable   \n",
    "c) print the reshaped array shape by printing new_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise:\n",
    "1. train the model using the reshaped image\n",
    "2. predict using the same reshaped image (_Note_: we would typically want to test the quality of the segmentation on data not used for training)\n",
    "3. reshape the predicted output to the original image shape (using `output.reshape(image.shape)`\n",
    "4. display it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Let's display the segmented image together with the original image and ground truth mask\n",
    "\n",
    "The ground truth mask can be found on the same path as the original image with name \"`wt_mask.tif`\".  \n",
    "Use `imread` again to load it.  \n",
    "  \n",
    "We can use matplotlib subplots to display multiple images at once:\n",
    "```python\n",
    "\n",
    "plt.figure(figsize=(15, 10)) # sets the overall size for the figure\n",
    "\n",
    "plt.subplot(n_rows, n_cols, image_position) # since we have 3 images, let's use 1 row and 3 columns\n",
    "# image position will start at 1 and increment by 1 at each image\n",
    "plt.title(\"Image Title\")\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off') # just to make it look better to remove unnecessery axis which occupy space in the image frame\n",
    "```\n",
    "\n",
    "Step-by-step:\n",
    "1. read the ground truth image\n",
    "2. display original image\n",
    "3. display ground truth image\n",
    "4. display the segmentation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eye test tells us that the segmentation result is not so bad, but we shouldn't relly on our eyes for it.\n",
    "How can we properly evaluate the quality of segmentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Metrics for image segmentation quality\n",
    "There are several metrics to evaluate the quality of segmentation. In this example, we will use the Intersection over Union (IoU) metric:  \n",
    "  \n",
    "<img src=\"https://viso.ai/wp-content/uploads/2024/01/IoU-Formula.jpg\" width=600>\n",
    "\n",
    "This metric will output a score ranging from 0 (bad) to 1 (good).\n",
    "\n",
    "---\n",
    "\n",
    "### Implement your own IoU function\n",
    "\n",
    "1. First we need to make sure that both ground truth image and the segmentation have the desired data type when playing with masks (booleans: True/False).  \n",
    "    - We can do this by using the [astype](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.astype.html) method and Python's bool datatype.  \n",
    "\n",
    "2. Then we need to calculate the intersection between the masks. With booleans, this can be achieved by doing a logical `and` operation to check which elements are in both masks:\n",
    "    - using numpy's [logical_and](https://numpy.org/doc/2.0/reference/generated/numpy.logical_and.html) method\n",
    "\n",
    "3. Followed by the union, which can be achieved with a logical `or` operation, checking which pixels are in union of both masks:\n",
    "    - using [logical_or](https://numpy.org/doc/2.0/reference/generated/numpy.logical_or.html) method\n",
    "\n",
    "And finally we can calculate IoU as:\n",
    "```python\n",
    "iou_score = float(np.sum(intersection) / np.sum(union))\n",
    "# np.sum will count the number of pixels in the intersection and union that have a value of True (== 1)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Use the following skeleton to define the iou function:\n",
    "```python\n",
    "def iou(image1, image2):\n",
    "    # mask_1 data type as bool\n",
    "    # mask_2 data type as bool \n",
    "    \n",
    "    # calculate the intersection\n",
    "    # calculate the union\n",
    "\n",
    "    # return the iou score\n",
    "    return iou_score\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly created function to calculate the IoU score for the segmentation result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Repeat the same task by yourself using `../data/images/wt_membrane.tif`\n",
    "\n",
    "- Load the image\n",
    "- Normalize the intensities\n",
    "- Reshape the image using `.reshape((-1, 1))`\n",
    "- Train a KMeans model with your new image\n",
    "- Predict the segmentation with your new image\n",
    "- Reshape the predicted output to the original image shape `.reshape(image.shape)\n",
    "- Display the result and evaluate the quality of segmentation using the IoU function\n",
    "\n",
    "Always feel free to ask for help :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Using Supervised Machine Learning for segmentation\n",
    "\n",
    "Supervised machine learning require pairs of inputs and labels.\n",
    "For this exercise we will use the [Random Forest classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "\n",
    "Let's start by loading the images we want to segment using the [imread](https://scikit-image.org/docs/stable/api/skimage.io.html#skimage.io.imread) function of scikit-image, found in the io module.  \n",
    "  \n",
    "  \n",
    "Start by using the image found in `../data/images/wt_dna.tif` and don't forget to normalize the intensities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Manually creating labels to train our classifier\n",
    "\n",
    "We can create an annotation image by using the [zeros_like](https://numpy.org/doc/stable/reference/generated/numpy.zeros_like.html) function and then manually assigning the labels in the new array.  \n",
    "   \n",
    "  \n",
    "  \n",
    "Let's use label `1` for background and `2` for cells.\n",
    "   \n",
    "```python\n",
    "labels = np.zeros_like(image)\n",
    "labels[row_start:row_end, col_start:col_end] = 1 # background\n",
    "labels[row_start:row_end, col_start:col_end] = 2 # cell\n",
    "```\n",
    "\n",
    "Use the following indexes for background:\n",
    "- [200:220, 730:750]  \n",
    "  \n",
    "And for cells:\n",
    "- [260:270, 335:345]\n",
    "- [305:315, 595:605]\n",
    "\n",
    "This process of training on only partially labelled data is often refered to as shallow learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Adding extra features to the training data\n",
    "Although we could actually train with just the pixel values, they may not contain enough information to do a good job. It would be a more expensive way of doing a simple intensity threshold wihtout improving on it. \n",
    "\n",
    "So, we can add more features to the training data to increase the classifier power. \n",
    "This is especially important when we are performing shallow learning as, otherwise, the classifier wouldn't have enought data to actually learn meaningful differences.\n",
    "  \n",
    "\n",
    "For this we are going to create a custom function to generate features from the image.\n",
    "These features can be many things, but often a good starting point is to apply several filters to the image and use the output as features.\n",
    "We will be using [scikit-image filters](https://scikit-image.org/docs/dev/api/skimage.filters.html) module for this.\n",
    "Let's try to use:\n",
    "- [gaussian](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.gaussian)\n",
    "- [sobel](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.sobel) (edge detection)\n",
    "- [median](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.median)\n",
    "\n",
    "_Note_: Don't forget that, as before, we need our data to be in shape `(n_samples, n_features)`.\n",
    "\n",
    "Use the following skeleton for the new custom function:   \n",
    "\n",
    "```python\n",
    "def generate_feature_stack(image):\n",
    "    # determine features\n",
    "    features_1 = filters.filter_1(image) # don't forget to add the filter parameters if needed\n",
    "    features_2 = filters.filter_2(image)\n",
    "    features_3 = filters.filter_3(image)\n",
    "\n",
    "    feature_stack = [\n",
    "        image.ravel(), # .ravel() reshapes a n-dimensional array into a 1-D image.\n",
    "        features_1.ravel(),\n",
    "        ...\n",
    "    ]\n",
    "\n",
    "    return np.asarray(features_stack) # convert the feature stack into a numpy array\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next:\n",
    "1. use the newly defined function to create the feature stack for our normalized image\n",
    "2. display the features usign the matplotlib `imshow` function. __Note__: We need to reshape the features in order to display them as 2D images.\n",
    "   \n",
    "```python\n",
    "features = generate_feature_stack(image)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(1, 3, 1) # set according to the number of features\n",
    "plt.title('Feature 1') \n",
    "plt.imshow(features[0].reshape(image.shape), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# do the same for the remaining features\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Bonus__:\n",
    "These images are too small to see the effect of our filters.\n",
    "Let's crop the image, as we did yesterday, and display a smaller region of interest.\n",
    "\n",
    "_Hint_: use start and stop indexes for `x` and `y` coordinates and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Format the data according to scikit-learn requirements.\n",
    "Since we have only partially labelled images, we need to create the training arrays with just the pixels that have been annotated.\n",
    "\n",
    "We can use numpy index filtering to remove all pixels from the `feature` and `labels` arrays which have not been annotated.\n",
    "\n",
    "Let's create our own custom function that performs this for both the `feature` stack and `labels`.  \n",
    "```python\n",
    "def format_data(feature_stack, annotation):\n",
    "    # start let's use ravel to make annotations a 1D array\n",
    "    y = annotation.ravel()\n",
    "    # then transpose the feature stack so that each feature will have the same indexes as the annotations\n",
    "    X = feature_stack.T\n",
    "\n",
    "    # start by creating a binary mask on labelled pixels\n",
    "    mask = y > 0 # creates a mask of True and False\n",
    "\n",
    "    # then we removel all pixels from the feature and annotations which have not been annotated\n",
    "    # apply the mask\n",
    "    X = X[mask] # with numpy arrays this allows us to select only the pixels that are True in the mask array\n",
    "    y = y[mask]\n",
    "\n",
    "    return X, y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply this function to the feature stack and the annotations to generate the formated data and store them in variables called `X_train` and `y_train`. \n",
    "\n",
    "In machine learning contexts, it is common to use \"X\" and \"Y\" variables for data and labels, respectively, which are not to be confused with the dimensions of image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Let's train the random forest classifier\n",
    "Now we use the training data we just prepared to train a new random forest model.\n",
    "\n",
    "Remember that all scikit-learn models have roughly the same API so we do the following:   \n",
    "   \n",
    "\n",
    "```python\n",
    "from sklearn.model_module import Model\n",
    "model = Model()\n",
    "model.fit(X_data2train, y_data2train) # now we need to pass both data (X) and labels (y)\n",
    "output = model.predict(data2predict) # same shape as data2train\n",
    "# then we need to reshape the output to the desired shape\n",
    "```\n",
    "\n",
    "The Random Forest classifier is part of the ensemble module of scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Segment the whole image using the trained classifier.\n",
    "\n",
    "Let's:\n",
    "1. do the prediction using the generated_feature_stack (don't forget to transpose it)\n",
    "2. visualize the original image, ground truth and prediction\n",
    "3. measure the IoU score using the previously created function\n",
    "\n",
    "---\n",
    "\n",
    "IMPORTANT:\n",
    "- we need to subtract one from the prediction before calling the iou function because the labels start at 1 and our ground truth starts at 0.\n",
    "This can be achieved by:   \n",
    "```python\n",
    "prediction = classifier.predict(feature_stack.T) - 1\n",
    "```\n",
    "- we also need to reshape the prediction back to the original image shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. (Optional, skip) Let's use napari to create a better annotation image\n",
    "\n",
    "<img src=\"https://napari.org/stable/_static/images/draw_component.png\" width=300>\n",
    "\n",
    "1. On BAND open napari and load the `wt_dna.tif` image there.\n",
    "2. Create a new label layer\n",
    "3. Use the drawing tool to label background with 1 and cells with 2\n",
    "4. Save the label layer as `wt_labels.tif`\n",
    "5. load the annotations here and repeat the steps from above:\n",
    "    - format data\n",
    "    - train classifier\n",
    "    - predict, visualize and measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Let's try another supervised algorithm: K-Nearest Neighbors\n",
    "This classifiers uses a parameter `k`, which is the number of nearest neighbors. The default value is 5.\n",
    "It is the supervised equivalent of the k-means clustering algorithm.\n",
    "\n",
    "Remember that all scikit-learn models have roughly the same API so we do the following:\n",
    "```python\n",
    "from sklearn.model_module import Model\n",
    "model = Model()\n",
    "model.fit(X_data2train, y_data2train) # now we need to pass both data (X) and labels (y)\n",
    "output = model.predict(data2predict) # same shape as data2train\n",
    "# then we need to reshape the output to the desired shape\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "[KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) is part of the neighbors module of scikit-learn.\n",
    "\n",
    "Let's:\n",
    "1. Use the previously defined X_train and y_train to train the new classifier\n",
    "2. predict the segmentation using the transposed feature stack\n",
    "3. visualize the original image, ground truth and prediction\n",
    "4. measure the IoU score using the previously created function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Repeat the task now for the sle1 images, feel free to try either membrane, dna or phase_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioimagecourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
