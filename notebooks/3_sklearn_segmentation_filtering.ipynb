{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using scikit-learn classification to filter out badly segmented cells\n",
    "\n",
    "In this notebook we are going to train a classifier to automatically filter out badly segmented cells using morphological measurements.   \n",
    "We will be covering:\n",
    "1. Instance segmentation from a binary image\n",
    "2. Measuring morphological features\n",
    "3. Training a classifier on manually annotated data of well and badly segmented cells\n",
    "4. Filter out badly segmented cells using the trained classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Let's start by installing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy scikit_image scikit_learn matplotlib pandas -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performing instance segmentation from a binary image using scikit-image\n",
    "Similarly to day 2 exercises we will perform instance segmentation from a binary image.  \n",
    "\n",
    "---\n",
    "\n",
    "For that we will start by loading the phase contrast image (`../data/images/wt_phase_contrast.tif`) and the binary mask image (`../data/images/wt_mask.tif`):   \n",
    "\n",
    "Let's load the images seperately and show them with `matplotlib` using `subplots`.\n",
    "\n",
    "Step-by-step: \n",
    "1. import the `skimage` module to load images\n",
    "    - _hint_: such as done earlier using `imread`\n",
    "1. load each image into a separate variable\n",
    "1. display each image as a subplot using `matplotlib`\n",
    "\n",
    "--- \n",
    "```python\n",
    "from skimage.io import imread\n",
    "phase = imread(\"path/to/phase_contrast\")\n",
    "mask = imread(\"path/to/binary_mask\")\n",
    "```  \n",
    "\n",
    "---\n",
    "Let's use matplotlib to display it:   \n",
    "```python\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 5)) # set the figure size\n",
    "plt.subplot(1, 2, 1) # create a subplot on a 1x2 grid\n",
    "plt.title('Phase Constrast') # set the title\n",
    "plt.imshow(phase, cmap='gray') # display the image\n",
    "plt.axis('off') # turn off the axis\n",
    "\n",
    "# do the same for the second subplot. hint: use plt.subplot(1, 2, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performing the instance segmentation\n",
    "\n",
    "Some cells have an opening in the binary mask, we can fill it using scipy [`binary_fill_holes`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.binary_fill_holes.html) from the [`ndimage`](https://docs.scipy.org/doc/scipy/reference/ndimage.html) module.   \n",
    "```python\n",
    "from scipy.ndimage import binary_fill_holes\n",
    "filled_mask = binary_fill_holes(mask)\n",
    "```\n",
    "   \n",
    "Display the result using `matplotlib` `imshow` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have touching cells forming a much larger mask  which does not accurately represent the cell.\n",
    "So, we want to split the masks to get individual cells. We will be using the `watershed` algorithm to split masks.\n",
    "\n",
    "The `watershed` algorithm needs additional information before splitting the masks. It needs markers (also known as seeds) to define the center of the cell masks, and a distance map which creates an image of the distance of each pixel to the mask border.\n",
    "\n",
    "First, let's start by creating a distance map.  \n",
    "\n",
    "--- \n",
    "\n",
    "For this we can use `scipy` distance transform from the [ndimage](https://docs.scipy.org/doc/scipy/reference/ndimage.html) module.\n",
    "\n",
    "```python\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "distances = distance_transform_edt(filled_mask)\n",
    "```\n",
    "   \n",
    "Display the result using matplotlib imshow function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to create an image with only the markers. We will use the local maxima of the distance map to get an approximate center of the cells.\n",
    "\n",
    "For this we can use scikit-image [`peak_local_max`](https://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.peak_local_max) from the [`skimage.feature`](https://scikit-image.org/docs/stable/api/skimage.feature.html) module to get a list of coordinated for the local maxima.\n",
    "\n",
    "However, since we only get a list of coordinates, we need to create an image with only the local maxima.\n",
    "Then we will create an empty image using `numpy` `zero_like` function and assign a value of `True` to each local maxima.   \n",
    "\n",
    "---\n",
    "And finally we will add individual labels for each local maxima using the [label](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.label.html#scipy.ndimage.label) function from `scipy.ndimage` module.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.ndimage import label\n",
    "coordinates = peak_local_max(distances, labels=filled_mask) # extract the local maxima coordinates\n",
    "coordinates_tuple = tuple(coordinates.T) # convert the coordinates to a tuple to allow numpy array indexing\n",
    "local_maxima = np.zeros_like(filled_mask, dtype=bool) # create an empty image\n",
    "local_maxima[coordinates_tuple] = True # assign a value of True to the local maxima\n",
    "markers = label(local_maxima)[0] # add individual label (ID) for each local maxima\n",
    "```\n",
    "\n",
    "Step-by-step:\n",
    "1. from the distance transform image, get a list of local maxima\n",
    "1. create an empty image with the same shape as the original\n",
    "1. assign a value of `True` to the pixel coordinates in the local maxima\n",
    "1. add an individual label to each marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can apply the [`watershed`](https://scikit-image.org/docs/stable/api/skimage.segmentation.html#skimage.segmentation.watershed) algorithm from scikit-image.   \n",
    "\n",
    "_Note_: for historical reasons, the `watershed` expects darker intensity values as the objects, so we need to invert the distance map. \n",
    "\n",
    "```python\n",
    "labels = watershed(-distance_map, markers, mask=filled_mask) # we need to use the inverted distance transform\n",
    "```\n",
    "\n",
    "---\n",
    "To better visualize if the `watershed` did a good job, we will assign random colors to each cell mask (for display purposes only), [`label2rgb`](https://scikit-image.org/docs/stable/api/skimage.color.html#skimage.color.label2rgb) function from the `color` module of scikit-image does the trick.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "from skimage.color import label2rgb\n",
    "colored_labels = label2rgb(labels, bg_label=0)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Use the `matplotlib` `imshow` function to display the overlay as well as a cropped version of the overlay.\n",
    "Use indexes [200:500, 200:600] to zoom in.\n",
    "```python\n",
    "plt.imshow(colored_labels[200:500, 200:600], cmap='gray')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we run the watershed algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filtering out badly segmented cells using a classification algorithm\n",
    "As you can see in the zoomed in colored image, some cells are not properly segmented.  \n",
    "We will try to train a classifier to automatically classify well and badly segmented cells and then filter out badly segmented cells.  \n",
    "\n",
    "---\n",
    "\n",
    "The data in the `segmentation_quality.csv` file contains morphological measurements of segmented cells with an extra column of manual annotations \"Well Segmented\":   \n",
    "- 0 = badly segmented\n",
    "- 1 = well segmented\n",
    "\n",
    "---\n",
    "\n",
    "Start by taking a look at the data by reading it using `pandas`.   \n",
    "```python\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"../data/segmentation_quality.csv\")\n",
    "data.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did in Notebook #2, we need to shuffle and standardize the data. Feel free to look at step 5 of that notebook and reuse the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train a `LogisticRegression` classifier to automatically classify well and badly segmented \n",
    "Look at how you solved the classification problem in the previous notebook to complete the next steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Shuffle and separate the data both into training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Train a `LogisticRegression` classifier and plot it's confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Use the model to filter out badly segmented cells\n",
    "Let's start by measuring the morphological features of the segmented cells.   \n",
    "For that we will be using [`regionprops_table`](https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops_table) from `skimage.measure`.   \n",
    "\n",
    "Then we will convert the table to a `pandas` dataframe.\n",
    "\n",
    "```python\n",
    "from skimage.measure import regionprops_table\n",
    "measurements = regionprops_table(labels, properties=[\"property_1\", \"property_2\", ...])\n",
    "measurements = pd.DataFrame.from_dict(measurements)\n",
    "```\n",
    "\n",
    "The properties we want to measure are: `label`, `area`, `perimeter`, `axis_major_length`, `axis_minor_length`, `eccentricity`.\n",
    "\n",
    "---\n",
    "\n",
    "We can then need to rename them to match the dataset names:\n",
    "\n",
    "```python\n",
    "measurements = measurements.rename(columns={'old_name_1':'new_name_1', 'old_name_2':'old_name_2', ...})\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "And finally, we look at the table:\n",
    "```python\n",
    "measurements.head()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalized the measurements as we did for the training data.   \n",
    "However, we need to normalize it according to the mean and standard deviation of the training data.   \n",
    "We can adapt the code from the `normalize_column` function we used before:\n",
    "```python\n",
    "def normalize_column_test(data_column, mean, std):\n",
    "    # notice that now we pass the mean and std as arguments\n",
    "\n",
    "    normalized_column = (data_column - mean) / std\n",
    "\n",
    "    return normalized_column\n",
    "\n",
    "normalized_measurements[col] = normalize_column_test(measurements[col], data[col].mean(), data[col].std())\n",
    "```\n",
    "Don't forget to store the normalized table in the variable `normalized_measurements`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use our trained model to predict whether each cell is well or badly segmented.   \n",
    "We do this by:   \n",
    "1. Use the classifier to predict   \n",
    "\n",
    "```python\n",
    "predictions = classifier.predict(measurements[columns_list])\n",
    "```\n",
    "\n",
    "2. Create a copy of the labels image   \n",
    "\n",
    "```python\n",
    "filtered = labels.copy()\n",
    "```\n",
    "\n",
    "3. Loop through the labels column of regionprops_table and set the label to 0 if the prediction is 0   \n",
    "\n",
    "```python\n",
    "for index, label in enumerate(measurements['label']):\n",
    "    if predictions[index] == 0:\n",
    "        filtered[filtered == label] = 0 # sets all pixels where the value is equal to label to 0\n",
    "```\n",
    "\n",
    "4. Color the filtered_labels as we did for the original labels (hint: label2rgb)   \n",
    "\n",
    "5. Display the cropped version (use indices [200:500, 200:600]) of both original and filtered labels using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exercise: Apply the same steps to the sle1 images\n",
    "\n",
    "You can find them under `../data/images/` with names starting with `sle1_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exercise: Try a different classifier\n",
    "\n",
    "You can find a list of other scikit-learn models [here](https://scikit-learn.org/stable/supervised_learning.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioimagecourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
